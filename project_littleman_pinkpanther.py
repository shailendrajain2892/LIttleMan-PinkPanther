# -*- coding: utf-8 -*-
"""project_littleman_pinkpanther

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QwzQc-CaYOuxq0OpAYR_BE-jy0ibHGW4
"""

from google.colab import drive
drive.mount('/content/drive', force_remount=True)

import numpy as np
import cv2
import matplotlib.pyplot as plt
import math
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt 
from keras.utils import np_utils
from skimage.transform import resize
import warnings
warnings.filterwarnings('ignore')
import os

os.chdir('/content/drive/My Drive/Colab Notebooks/project-littleman-pinkpanther')

path1 = '/content/drive/My Drive/Colab Notebooks/project-littleman-pinkpanther/littleman_pinkpanther.webm'

def get_images_from_video(video_path, save_images_dir=None):
  videoFile = video_path
  imagesFolder = save_images_dir or '/content/drive/My Drive/Colab Notebooks/project-littleman-pinkpanther/video_images'
  cap = cv2.VideoCapture(videoFile)
  frameRate = round(cap.get(5)) #frame rate
  print("FrameRate for the Video is {}".format(frameRate))
  currentframe = 1
  if not os.path.isdir(imagesFolder):
      os.mkdir(imagesFolder)
  while(cap.isOpened()):
      frameId = cap.get(1) #current frame number
      ret, frame = cap.read()
      if (ret != True):
          break
      if frameId % frameRate == 0:
          filename = imagesFolder + "/image_" +  str(int(frameId)) + ".jpg"
          print("Creating {}...{}".format(currentframe, filename))
          cv2.imwrite(filename, frame)
          currentframe += 1
  cap.release()
  cv2.destroyAllWindows() 
  print( "Done!")
  return frameRate

get_images_from_video(path1)

"""**Create Mapping CSV file of Video Files, to train VGG16 model**"""

data = pd.read_csv('./panther_littleman_mapping.csv')

X = data.image_id

y = data['class']

"""**Check for class Imbalance**"""

sns.countplot(y)

"""**Read Images into Array**"""

images_read_array = []
for img in data.image_id:
  img_read = plt.imread("./video_images/{}.jpg".format(img))
  images_read_array.append(img_read)

"""**Check for size of each image**"""

images_read_array[0].shape

"""Convert array to nparray"""

images_read_array = np.array(images_read_array)

"""Since there are Four classes, 

0.   Other
1.   Pink Panther
2.   Little Man
3.   Both

we will one hot encode them using the to_categorical() function
"""

dummy_y = np_utils.to_categorical(y)

dummy_y.shape

"""We will be using a VGG16 pretrained model which takes an input image of shape (224 X 224 X 3).  We will use the resize() function of skimage.transform to do this."""

images = []
for i in range(images_read_array.shape[0]):
  a = resize(images_read_array[i], preserve_range=True, output_shape=(224,224)).astype(int)
  images.append(a)
  
images_read_array = np.array(images)

"""All the images have been reshaped to 224 X 224 X 3. But before passing any input to the model, we must preprocess it as per the modelâ€™s requirement. Otherwise, the model will not perform well enough. Use the preprocess_input() function of keras.applications.vgg16 to perform this step."""

images_read_array[0].shape

from keras.applications.vgg16 import preprocess_input
images_read_array = preprocess_input(images_read_array, mode='tf')

"""We also need a validation set to check the performance of the model on unseen images. We will make use of the train_test_split() function of the sklearn.model_selection module to randomly divide images into training and validation set."""

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(images_read_array, dummy_y, test_size=.3, random_state=42)

X_train.shape

X_test.shape

"""# **Build the Model**

The next step is to build our model. As mentioned, we shall be using the VGG16 pretrained model for this task. Let us first import the required libraries to build the model:
"""

from keras.models import Sequential
from keras.applications.vgg16 import VGG16
from keras.layers import Dense, InputLayer, Dropout

"""We will now load the VGG16 pretrained model and store it as base_model:"""

base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))  # include_top=False to remove the top layer

"""We will make predictions using this model for X_train and X_test, get the features, and then use those features to retrain the model."""

X_train = base_model.predict(X_train)
X_test = base_model.predict(X_test)

X_train.shape, X_test.shape

"""The shape of X_train and X_test is (268, 7, 7, 512), (116, 7, 7, 512) respectively. In order to pass it to our neural network, we have to reshape it to 1-D."""

X_train = X_train.reshape(268, 7*7*512)      # converting to 1-D
X_test = X_test.reshape(116, 7*7*512)

"""We will now preprocess the images and make them zero-centered which helps the model to converge faster."""

train = X_train/X_train.max()      # centering the data
X_test = X_test/X_train.max()

"""Finally, we will build our model. This step can be divided into 3 sub-steps:

1. Building the model
2. Compiling the model
3. Training the model
"""

# i. Building the model
model = Sequential()
model.add(InputLayer((7*7*512,)))    # input layer
model.add(Dense(units=512, activation='sigmoid')) # hidden layer
model.add(Dense(4, activation='softmax'))    # output layer

model.summary()

"""We have a hidden layer with 1,024 neurons and an output layer with 4 neurons (since we have 4 classes to predict). Now we will compile our model:"""

# ii. Compiling the model
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

"""In the final step, we will fit the model and simultaneously also check its performance on the unseen images, i.e., validation images:"""

# iii. Training the model
model.fit(train, y_train, epochs=300, validation_data=(X_test, y_test))

"""We can see it is performing really well on the training as well as the validation images. We got an accuracy of around 85% on unseen images. And this is how we train a model on video data to get predictions for each frame."""

def predict_image_class(image, image_dir=None):
  img_dir = image_dir or './video_images/'
  img = np.array(plt.imread( img_dir + image))
  a = np.array(resize(img, preserve_range=True, output_shape=(224,224)).astype(int))
  a =  np.expand_dims(a, axis=0)
  # preprocessing the images
  test_image = preprocess_input(a, mode='tf')

  # extracting features from the images using pretrained model
  test_image = base_model.predict(test_image)

  # converting the images to 1-D form
  test_image = test_image.reshape(1, 7*7*512)

  # zero centered images
  test_image = test_image/test_image.max()
#   print( model.compute_output_shape(test_image))
  return img, model.predict_classes(test_image)

from imutils import paths
import imutils
from google.colab.patches import cv2_imshow

def predict_image_classes(model, imageDir=None, saveDir=None, frameRate=None):
  class_map = {0:'Other',
              1:'PinkPanther',
              2:'LittleMan',
              3:'Both'}
  framerate = frameRate or 30
  seconds_in_minute = 60
  save_dir = saveDir or './video_images_predicted/'
  if not os.path.isdir(save_dir):
      os.mkdir(save_dir)
  currentframe = 1
  for filename in os.listdir(imageDir or './video_images/'):
    img, object_class = predict_image_class(filename, imageDir or './video_images/')
    if object_class[0] != 0:
      currentframe +=1
      object_name = class_map.get(object_class[0])
      # draw the label on the image
      output = imutils.resize(img, width=400)
      cv2.putText(output, object_name, (10, 25),  cv2.FONT_HERSHEY_SIMPLEX,
        0.7, (0, 255, 0), 2)
      cv2_imshow(output)   
      image_num = filename.split('_')[1].split('.')[0]
      newfilename = str(round(int(image_num)/framerate*seconds_in_minute, 2)).replace('.', '_')+'.jpg'
      cv2.imwrite(save_dir+newfilename, img)
      print("Saving Image:{}, {}".format(filename, newfilename))
  cv2.destroyAllWindows() 
  print( "Done!")

predict_image_classes(model)

def predict_test_video_images(model, videoFile, saveDir):
  image_dir = './test_video_images/'
  frame_rate = get_images_from_video(videoFile, image_dir)
  predict_image_classes(model, image_dir, saveDir, frame_rate)

predict_test_video_images(model,
          '/content/drive/My Drive/Colab Notebooks/project-littleman-pinkpanther/test_video.webm',
          './test_predicted_images')